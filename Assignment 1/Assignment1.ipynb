{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSF 544 Data Science for Software Engineers\n",
    "**Assignment 1** - 100 marks\n",
    "\n",
    "**Due:** September 20th, 12pm.\n",
    "\n",
    "\n",
    "**IMPORTANT NOTE: each task must be implemented as asked, even if there are other easier or better solutions.**\n",
    "\n",
    "**How to deliver:**\n",
    "Edit this file and write your solutions in sections specified with `# Your solution`. Test your code and when you were done, submit this notebook as an `.ipynb` file to D2L dropbox. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - The Zipf mystery (50 points)\n",
    "\n",
    "In this problem, we'd like to read the text from a book and perform some simple statistical analysis on the word counts. We have provided you with the actual text from [Lost On The Moon or, In Quest of the Field of Diamonds](https://www.goodreads.com/book/show/8636132-lost-on-the-moon-or-in-quest-of-the-field-of-diamonds) book in a file named 'the book.txt'. The file is cleaned up and only contains alphanumeric characters, i.e. no punctuation, quotation marks, etc.\n",
    "\n",
    "Read the file and break it down to its words. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'latter', 'picked', 'it', 'up', 'gazed', 'at', 'it', 'first', 'from']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_and_tokenize(file_name):\n",
    "    openedFile = open(file_name, 'r') # open the file\n",
    "    return openedFile.read().split() # then read it, splitting it by whitespace\n",
    "\n",
    "words = read_and_tokenize('the book.txt')\n",
    "words[1101:1111] # Expected: ['the', 'latter', 'picked', 'it', 'up', 'gazed', 'at', 'it', 'first', 'from']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a sorted list of unique words in the book. Store the list in a variable called `V`. Also complete the `get_word_index` function below that gets a word and finds its index within `V`. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = read_and_tokenize('the book.txt') # make the word list first\n",
    "V = [] \n",
    "for i in words: # iterate through the word list...\n",
    "    if i not in V: # and if it's not already in V...\n",
    "        V.append(i) # add it\n",
    "V.sort()\n",
    "\n",
    "def get_word_index(word): \n",
    "    return V.index(word) # self-explanatory\n",
    "\n",
    "get_word_index('about')  # Expected: 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using no loops, and by only using `map` and `filter` built-in python functions traverse through the `V` (vocabulary) list above to find:\n",
    "\n",
    "* `long_words`: The list of words that have 10 letters or more \n",
    "* `no_vowels`: A list of all words but with vowels (aoeiu) removed. You can nest `map` and `filter` calls to iterate through the characters of the words.\n",
    "\n",
    "(5+5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consonants_only(letter):\n",
    "    the_vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    if letter in the_vowels:\n",
    "         return False\n",
    "    else:\n",
    "         return True\n",
    "\n",
    "long_words = filter(len(V) >= 10, V)\n",
    "no_vowels = map(consonants_only, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a python dictionary named `frequencies` (using defaultdict would make things easier). Use this dictionary to count the number of times each word has appeared in the book. For example `frequencies['about']` should store how many times the word \"about\" has been appeared in the book (165 times). (10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your solution\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def default_value():\n",
    "    return 0\n",
    "\n",
    "frequencies = defaultdict(default_value)\n",
    "for i in words:\n",
    "    frequencies[i] += 1\n",
    "\n",
    "frequencies['about'] # Expected: 165.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the word that appeared most frequently in the book. Find the word itself as well as the number of times it was repeated in the book. Use python's built-in max() function but define your own key using lambda function, i.e. do not iterate over the `frequencies` dictionary manually using a `for` loop. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the\" is the most common word which has appeared 3237 times in the book.\n"
     ]
    }
   ],
   "source": [
    "# Your solution \n",
    "most_common_word = max(frequencies, key = frequencies.get)\n",
    "max_frequency = frequencies[most_common_word]\n",
    "\n",
    "print(f'\"{most_common_word}\" is the most common word which has appeared {max_frequency} times in the book.')\n",
    "# Expected: \"the\" is the most common word which has appeared 3237 times in this book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all frequency values by dividing them by the maximum frequency value (using map). After this the most common word in the book should get a normalized frequency of `1` and all other words get some value \n",
    "between `1/MAX` and `1`. (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution\n",
    "\n",
    "def normalize(num):\n",
    " return 1/max_frequency\n",
    "\n",
    "normalized_frequencies = map(normalize, frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check if the normalized frequencies have any correlation to their ranks. If such correlation exists, the Zipf's law states that it is linear in a log-log space. Take the logarithm of normalized frequencies (as x values) and create a list of the same size containing the rank of each word (as y values). For example if the frequencies are `[0.1, 0.1, 1, 0.01, 0.0001]` the x and y values will be `Y = [2, 2, 1, 4, 5] X=[-1, -1, 0, -2, -4]`.\n",
    "(Note that same normalized values should have the same rank)\n",
    "\n",
    "You might want to sort the normalized frequencies first to make the task easier.  (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "y = list(normalized_frequencies).sort()\n",
    "x = [log(i) for i in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the [pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) on this data. The result is expected to be close to -1. Define the missing variables in the pcc function for the the statistical calculations as necessary (using python's built-in functions like map and sum).  (2.5+2.5+5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcc(x, y):\n",
    "  n = len(x)\n",
    "  sum_x = float(sum(x))\n",
    "  sum_y = float(sum(y))\n",
    "\n",
    "  ### Your solution goes here ###\n",
    "    \n",
    "  sum_x_sq = sum(x**2) # sum of squared x \n",
    "  sum_y_sq = sum(y**2) #sum of squared y\n",
    "  i = 0\n",
    "  psum = 0\n",
    "  while (x[i] != None):\n",
    "    psum += x[i] * y[i] #dot product of x,y using map\n",
    "  \n",
    "  #### your solution ends here### \n",
    "  num = psum - (sum_x * sum_y/n)\n",
    "  den = pow((sum_x_sq - pow(sum_x, 2) / n) * (sum_y_sq - pow(sum_y, 2) / n), 0.5)\n",
    "  if den == 0: return 0\n",
    "  return num / den\n",
    "    \n",
    "pcc(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can use `pearsonr` function from `scipy` package to check if the calculated value is definitely correct. Though if you get a value close enough to -1 you can almost be sure that your implementation is correct and this step won't be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell to see if your pcc function is correct\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "x = np.log(np.sort(normalized_frequencies)[::-1])\n",
    "y = np.arange(1, 1+len(V))\n",
    "\n",
    "pearsonr(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 - Log processing (50 points)\n",
    "\n",
    "In this part of the assignment we are going to use regular expressions to mine data out of some webserver log files. Although these problems can be solved without use of RegExes, but for this assignment you need to use them.\n",
    "\n",
    "A sample web server log file is provided along with this problem. In each line of the file one event is recorded. For simplicity all of the events in this file have the same format and are of the same type. Each event contains an ip address, date and time of the event, http method (`GET` or `POST`), a url, HTTP version, HTTP response code (usually 200), the response size in bytes, and the device's user agent which contains information about the device such as the brand and the operating system.\n",
    "\n",
    "Since these logs have such a well defined format regular expressions are the prefect tool for breaking them down into parts and perform different analysis on them.\n",
    "\n",
    "**Please make sure that when you are asked to write a function that _return_s something, you are _return_ing that value, not just _print_ing it**\n",
    "\n",
    "We start off with a random log line and write python functions that use regular expressions to break it off to pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.106.145.204 - - [04/Sep/2019:13:51:39 +0430] \"POST /v1/crash-report/incident/report/ HTTP/1.1\" 200 65 \"-\" \"Dalvik/1.6.0 (Linux; U; Android 4.2.2; GT-S7272 Build/JDQ39)\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "l = '5.106.145.204 - - [04/Sep/2019:13:51:39 +0430] \"POST /v1/crash-report/incident/report/ HTTP/1.1\" 200 65 \"-\" \"Dalvik/1.6.0 (Linux; U; Android 4.2.2; GT-S7272 Build/JDQ39)\"'\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function that extracts the ip address part of the log line using regular expressions. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 13), match='5.106.145.204'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ip_address(l):\n",
    "    return re.search(\"[0-9]+.[0-9]+.[0-9]+.[0-9]+\", l)\n",
    "\n",
    "\n",
    "get_ip_address(l)  # Expected: '5.106.145.204'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Make a function that extracts the operating system name and version using regular expressions. (5 points)\n",
    "\n",
    "Your Answer need to be general for the log file. (There are Windows, Linux, and Android operating systems in the log file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(133, 147), match='Android 4.2.2;'>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_os(l):\n",
    "    return re.search(\"(Windows |Linux |Android )(.+?);\", l)\n",
    "get_os(l) #Expected: 'Android 4.2.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function that extracts the HTTP method, url, response code, and response size and returns a tuple. Use regular expressions. The http method is either `POST` or `GET` and the response code is always a 3 digit integer. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(48, 156), match='POST /v1/crash-report/incident/report/ HTTP/1.1\" >"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_http_info(l):\n",
    "    return re.search(\"(POST|GET).*([0-9]{3})([0-9]+)\", l)\n",
    "\n",
    "get_http_info(l)  # Expected: ('POST', '/v1/crash-report/incident/report/', 200, 65)\n",
    "# Please note that the last two numbers are converted to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use regular expressions to break the date and time section apart and create a python datetime object based on that. Mind the time zone. convert the datetimes to MDT. Using `strptime` is a better solution in general, but for this assignment please stick to writing RegExes so you become more comfortable in writing and debugging them. (15 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from calendar import month_abbr\n",
    "\n",
    "MDT = timezone(timedelta(minutes=-6*60 + 0))\n",
    "\n",
    "def month_num(name):\n",
    "    return {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec':12}[name]\n",
    "\n",
    "def get_datetime(l):\n",
    "    return re.search(\"\\([0-9]+)-([0-9]+)-([0-9])+T([0-9]+):([0-9]+):([0-9]+)]\", l)\n",
    "\n",
    "x = get_datetime(l)\n",
    "\n",
    "y = datetime(x.group(3), month_num(x.group(2)), x.group(1), x.group(4), x.group(5), x.group(6))\n",
    "\n",
    "y.isoformat()  # Expected: '2019-09-04T03:21:39-06:00'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Read the log file line by line and use the `get_os` functions above to find all unique operating systems (including version) and print the sorted results (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "unique_sorted_os_list = []\n",
    "openedFile = open(\"log.txt\", 'r')\n",
    "openedLines = openedFile.readlines()\n",
    "\n",
    "for line in openedLines:\n",
    "    if (line not in unique_sorted_os_list)\n",
    "        unique_sorted_os_list.append(line)\n",
    "\n",
    "unique_sorted_os_list.sort()\n",
    "\n",
    "print('\\n'.join(unique_sorted_os_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the log file line by line and use the `get_datetime` and `get_http_info` functions above to calculate the used bandwidth of the server (the sum of all the response sizes) per hour. Use a `dict` or a `defaultdict`. (10 points)\n",
    "\n",
    "For example if there are 4 logs like:\n",
    "\n",
    "    Sep 4 14:20 .... 65bytes\n",
    "    Sep 4 14:35 .... 80bytes\n",
    "    Sep 4 15:01 .... 44bytes\n",
    "    Sep 5 18:20 .... 40bytes\n",
    "\n",
    "The result will be like:\n",
    "\n",
    "    Sep 4 14:00  145\n",
    "    Sep 4 15:00  44\n",
    "    Sep 5 18:00  40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = dict()\n",
    "list_bandwidths = []\n",
    "\n",
    "openedFile = open(\"log.txt\", 'r')\n",
    "openedLines = openedFile.readlines()\n",
    "\n",
    "for line in openedLines:\n",
    "    x = get_datetime(line)\n",
    "    y = get_http_info(line)\n",
    "    bandwidths = dict(\n",
    "        \"month\": month_num(x.group(2))\n",
    "        \"day\": x.group(1)\n",
    "        \"hour\": x.group(4)\n",
    "        \"bandwith\": y.group(3) # the 2nd number from the HTTP read\n",
    "    )\n",
    "    list_bandwidths.append(bandwidth)\n",
    "    for (band in list_bandwidths) {\n",
    "        if (band.hour = (band + 1).hour)\n",
    "            list_bandwidths[band].bandwith += list_bandwidths[band + 1].list_bandwidths\n",
    "            delete list_bandwitdths[band + 1]\n",
    "\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
